{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd93d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9f255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524c7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open('logreg_model_3months.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c69649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from datetime import datetime, timedelta\n",
    "from pylab import rcParams\n",
    "import pickle\n",
    "import importlib\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os\n",
    "\n",
    "from prepare_data import DataLoader\n",
    "from evaluate_results import EvaluateResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684e5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Hp/VS CODE/Stock market crash prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd23f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, datasets_original, dataset_names):\n",
    "        self.num_datasets = len(datasets_original)\n",
    "        self.datasets_original = datasets_original\n",
    "        self.dataset_names = dataset_names\n",
    "        self.datases_revised = None\n",
    "        self.drawdowns = None\n",
    "        self.crashes = None\n",
    "    \n",
    "    def get_data_revised(self, crash_thresholds):\n",
    "        datasets = []\n",
    "        print(datasets_original)\n",
    "        \n",
    "        for d in self.datasets_original:\n",
    "\n",
    "            data_original = pd.read_csv(d,index_col='Date')\n",
    "            print('csv_ read')\n",
    "            print(data_original)\n",
    "#             print(data_original.head(5))\n",
    "\n",
    "        \n",
    "            data_original.index = pd.to_datetime(data_original.index, format='%Y-%m-%d')\n",
    "            list(data_original.columns)\n",
    "            print(data_original)\n",
    "            data_norm = data_original['Close'] / data_original['Close'][-1]\n",
    "            data_ch = data_original['Close'].pct_change()\n",
    "            window = 10\n",
    "            data_vol = data_original['Close'].pct_change().rolling(window).std()\n",
    "            data = pd.concat([data_original['Close'], data_norm, data_ch, data_vol], axis=1).dropna()\n",
    "            data.columns = ['price', 'norm', 'ch', 'vol']\n",
    "            datasets.append(data)\n",
    "        self.drawdowns = []\n",
    "        self.crashes = []\n",
    "        for df, ct in zip(datasets, crash_thresholds):\n",
    "            pmin_pmax = (df['price'].diff(-1) > 0).astype(int).diff()\n",
    "            pmax = pmin_pmax[pmin_pmax == 1]\n",
    "            pmin = pmin_pmax[pmin_pmax == -1]\n",
    "            # make sure drawdowns start with pmax, end with pmin:\n",
    "            if pmin.index[0] < pmax.index[0]:\n",
    "                pmin = pmin.drop(pmin.index[0])\n",
    "            if pmin.index[-1] < pmax.index[-1]:\n",
    "                pmax = pmax.drop(pmax.index[-1])\n",
    "            D = (np.array(df['price'][pmin.index]) - np.array(df['price'][pmax.index]))/ np.array(df['price'][pmax.index])\n",
    "            d = {'Date':pmax.index, 'drawdown':D, 'd_start': pmax.index, 'd_end': pmin.index}\n",
    "            df_d = pd.DataFrame(d).set_index('Date')\n",
    "            df_d.index = pd.to_datetime(df_d.index, format='%Y-%m-%d')\n",
    "            df_d = df_d.reindex(df.index).fillna(0)\n",
    "            df_d = df_d.sort_values(by='drawdown')\n",
    "            df_d['rank'] = list(range(1,df_d.shape[0]+1))\n",
    "            self.drawdowns.append(df_d)\n",
    "            df_d = df_d.sort_values(by='Date')\n",
    "            df_c = df_d[df_d['drawdown'] < ct]\n",
    "            df_c.columns = ['drawdown', 'crash_st', 'crash_end', 'rank']\n",
    "            self.crashes.append(df_c)\n",
    "        self.datasets_revised = []  \n",
    "        for i in range(len(datasets)):\n",
    "            self.datasets_revised.append(pd.concat([datasets[i], self.drawdowns[i]], axis=1))\n",
    "        return self.datasets_revised, self.crashes\n",
    "    \n",
    "    def get_dfs_xy(self, months):\n",
    "    ### dfs_xy: dataframe for each dataset x (columns 0:-1) and  y (column -1)     \n",
    "        dfs_x, dfs_y = [], []\n",
    "        for df, c in zip(self.datasets_revised, self.crashes):\n",
    "            df['ch'] = df['ch'] / abs(df['ch']).mean()\n",
    "            df['vol'] = df['vol'] / abs(df['vol']).mean()\n",
    "            xy = {}\n",
    "            for date in df.index[252:-126]: # <--subtract 126 days in the end\n",
    "                xy[date] = list([df['ch'][(date-timedelta(5)):date].mean()])\n",
    "                xy[date].append(df['ch'][(date-timedelta(10)):(date-timedelta(5))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(15)):(date-timedelta(10))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(21)):(date-timedelta(15))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(42)):(date-timedelta(21))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(63)):(date-timedelta(42))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(126)):(date-timedelta(63))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(252)):(date-timedelta(126))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(5)):date].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(10)):(date-timedelta(5))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(15)):(date-timedelta(10))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(21)):(date-timedelta(15))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(42)):(date-timedelta(21))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(63)):(date-timedelta(42))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(126)):(date-timedelta(63))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(252)):(date-timedelta(126))].mean())\n",
    "                xy[date] = xy[date] + [max([date <= c and date + timedelta(month * 21) > c \\\n",
    "                          for c in c['crash_st']]) for month in months]\n",
    "            df_xy = pd.DataFrame.from_dict(xy, orient='index').dropna()\n",
    "            df_x = df_xy.iloc[:, :-len(months)]\n",
    "            df_y = df_xy.iloc[:, -len(months):]\n",
    "            dfs_x.append(df_x)\n",
    "            dfs_y.append(df_y)\n",
    "        return dfs_x, dfs_y\n",
    "    \n",
    "    def get_dfs_xy_predict(self, months):\n",
    "    ### dfs_xy: dataframe for each dataset x (columns 0:-1) and  y (column -1)     \n",
    "        dfs_x, dfs_y = [], []\n",
    "        for df, c in zip(self.datasets_revised, self.crashes):\n",
    "            df['ch'] = df['ch'] / abs(df['ch']).mean()\n",
    "            df['vol'] = df['vol'] / abs(df['vol']).mean()\n",
    "            xy = {}\n",
    "            for date in df.index: # <--subtract 126 days in the end\n",
    "                xy[date] = list([df['ch'][(date-timedelta(5)):date].mean()])\n",
    "                xy[date].append(df['ch'][(date-timedelta(10)):(date-timedelta(5))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(15)):(date-timedelta(10))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(21)):(date-timedelta(15))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(42)):(date-timedelta(21))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(63)):(date-timedelta(42))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(126)):(date-timedelta(63))].mean())\n",
    "                xy[date].append(df['ch'][(date-timedelta(252)):(date-timedelta(126))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(5)):date].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(10)):(date-timedelta(5))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(15)):(date-timedelta(10))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(21)):(date-timedelta(15))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(42)):(date-timedelta(21))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(63)):(date-timedelta(42))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(126)):(date-timedelta(63))].mean())\n",
    "                xy[date].append(df['vol'][(date-timedelta(252)):(date-timedelta(126))].mean())\n",
    "                xy[date] = xy[date] + [max([date <= c and date + timedelta(month * 21) > c \\\n",
    "                          for c in c['crash_st']]) for month in months]\n",
    "            df_xy = pd.DataFrame.from_dict(xy, orient='index').dropna()\n",
    "            df_x = df_xy.iloc[:, :-len(months)]\n",
    "            df_y = df_xy.iloc[:, -len(months):]\n",
    "            dfs_x.append(df_x)\n",
    "            dfs_y.append(df_y)\n",
    "        return dfs_x, dfs_y\n",
    "\n",
    "    def get_train_test(self, dfs_x, dfs_y, datasets, test_data):\n",
    "        for i, name in enumerate(datasets):\n",
    "            if name == test_data:\n",
    "                index = i\n",
    "        dfs_x_copy = list(dfs_x)\n",
    "        dfs_y_copy = list(dfs_y)\n",
    "        np_x_test = None\n",
    "        np_y_test = None\n",
    "        if test_data:\n",
    "            df_x_test = dfs_x_copy.pop(index)\n",
    "            df_y_test = dfs_y_copy.pop(index)\n",
    "            np_x_test = np.array(df_x_test)\n",
    "            np_y_test = np.array(df_y_test)\n",
    "        np_x_train = np.concatenate(([np.array(x) for x in dfs_x_copy]))\n",
    "        np_y_train = np.concatenate(([np.array(y) for y in dfs_y_copy]))\n",
    "        return np_x_train, np_y_train, np_x_test, np_y_test\n",
    "\n",
    "    def split_results(self, df_combined, dfs_xy, dataset_names, test_data, y_pred_t_bin, \\\n",
    "                      y_pred_tr_bin, y_train, y_test):\n",
    "        df_combined = [dfc.reindex(dfs.index) for dfc, dfs in zip(df_combined, dfs_xy)]\n",
    "        dfs_predict = []\n",
    "        n = 0\n",
    "        for df, name in zip(df_combined, dataset_names):\n",
    "            if name == test_data:\n",
    "                df['y'] = y_test\n",
    "                df['y_pred'] = y_pred_t_bin\n",
    "                dfs_predict.append(df)\n",
    "            else:\n",
    "                df['y'] = y_train[n:n+df.shape[0]]\n",
    "                df['y_pred'] = y_pred_tr_bin[n:n+df.shape[0]]\n",
    "                dfs_predict.append(df)\n",
    "                n += df.shape[0]\n",
    "        return dfs_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^GSPC.csv', '^N225.csv', 'SSE.csv', '^HSI.csv', '^BSESN.csv', '^SSMI.csv', '^BVSP.csv']\n",
      "csv_ read\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1950-01-03    16.660000    16.660000    16.660000    16.660000    16.660000   \n",
      "1950-01-04    16.850000    16.850000    16.850000    16.850000    16.850000   \n",
      "1950-01-05    16.930000    16.930000    16.930000    16.930000    16.930000   \n",
      "1950-01-06    16.980000    16.980000    16.980000    16.980000    16.980000   \n",
      "1950-01-09    17.080000    17.080000    17.080000    17.080000    17.080000   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-09-06  2888.639893  2892.050049  2867.290039  2878.050049  2878.050049   \n",
      "2018-09-07  2868.260010  2883.810059  2864.120117  2871.679932  2871.679932   \n",
      "2018-09-10  2881.389893  2886.929932  2875.939941  2877.129883  2877.129883   \n",
      "2018-09-11  2871.570068  2892.520020  2866.780029  2887.889893  2887.889893   \n",
      "2018-09-12  2888.290039  2894.649902  2879.199951  2888.919922  2888.919922   \n",
      "\n",
      "                Volume  \n",
      "Date                    \n",
      "1950-01-03     1260000  \n",
      "1950-01-04     1890000  \n",
      "1950-01-05     2550000  \n",
      "1950-01-06     2010000  \n",
      "1950-01-09     2520000  \n",
      "...                ...  \n",
      "2018-09-06  3139590000  \n",
      "2018-09-07  2946270000  \n",
      "2018-09-10  2731400000  \n",
      "2018-09-11  2899660000  \n",
      "2018-09-12  3264930000  \n",
      "\n",
      "[17286 rows x 6 columns]\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1950-01-03    16.660000    16.660000    16.660000    16.660000    16.660000   \n",
      "1950-01-04    16.850000    16.850000    16.850000    16.850000    16.850000   \n",
      "1950-01-05    16.930000    16.930000    16.930000    16.930000    16.930000   \n",
      "1950-01-06    16.980000    16.980000    16.980000    16.980000    16.980000   \n",
      "1950-01-09    17.080000    17.080000    17.080000    17.080000    17.080000   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-09-06  2888.639893  2892.050049  2867.290039  2878.050049  2878.050049   \n",
      "2018-09-07  2868.260010  2883.810059  2864.120117  2871.679932  2871.679932   \n",
      "2018-09-10  2881.389893  2886.929932  2875.939941  2877.129883  2877.129883   \n",
      "2018-09-11  2871.570068  2892.520020  2866.780029  2887.889893  2887.889893   \n",
      "2018-09-12  2888.290039  2894.649902  2879.199951  2888.919922  2888.919922   \n",
      "\n",
      "                Volume  \n",
      "Date                    \n",
      "1950-01-03     1260000  \n",
      "1950-01-04     1890000  \n",
      "1950-01-05     2550000  \n",
      "1950-01-06     2010000  \n",
      "1950-01-09     2520000  \n",
      "...                ...  \n",
      "2018-09-06  3139590000  \n",
      "2018-09-07  2946270000  \n",
      "2018-09-10  2731400000  \n",
      "2018-09-11  2899660000  \n",
      "2018-09-12  3264930000  \n",
      "\n",
      "[17286 rows x 6 columns]\n",
      "csv_ read\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1965-01-05   1257.719971   1257.719971   1257.719971   1257.719971   \n",
      "1965-01-06   1263.989990   1263.989990   1263.989990   1263.989990   \n",
      "1965-01-07   1274.270020   1274.270020   1274.270020   1274.270020   \n",
      "1965-01-08   1286.430054   1286.430054   1286.430054   1286.430054   \n",
      "1965-01-11           NaN           NaN           NaN           NaN   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-17           NaN           NaN           NaN           NaN   \n",
      "2018-09-18  23042.189453  23481.529297  23039.259766  23420.539063   \n",
      "2018-09-19  23754.960938  23842.050781  23672.519531  23672.519531   \n",
      "2018-09-20  23752.789063  23781.750000  23582.150391  23674.929688   \n",
      "2018-09-21  23848.630859  23971.410156  23764.050781  23869.929688   \n",
      "\n",
      "               Adj Close    Volume  \n",
      "Date                                \n",
      "1965-01-05   1257.719971       0.0  \n",
      "1965-01-06   1263.989990       0.0  \n",
      "1965-01-07   1274.270020       0.0  \n",
      "1965-01-08   1286.430054       0.0  \n",
      "1965-01-11           NaN       NaN  \n",
      "...                  ...       ...  \n",
      "2018-09-17           NaN       NaN  \n",
      "2018-09-18  23420.539063   90600.0  \n",
      "2018-09-19  23672.519531   93600.0  \n",
      "2018-09-20  23674.929688  101600.0  \n",
      "2018-09-21  23869.929688       0.0  \n",
      "\n",
      "[13844 rows x 6 columns]\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1965-01-05   1257.719971   1257.719971   1257.719971   1257.719971   \n",
      "1965-01-06   1263.989990   1263.989990   1263.989990   1263.989990   \n",
      "1965-01-07   1274.270020   1274.270020   1274.270020   1274.270020   \n",
      "1965-01-08   1286.430054   1286.430054   1286.430054   1286.430054   \n",
      "1965-01-11           NaN           NaN           NaN           NaN   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-17           NaN           NaN           NaN           NaN   \n",
      "2018-09-18  23042.189453  23481.529297  23039.259766  23420.539063   \n",
      "2018-09-19  23754.960938  23842.050781  23672.519531  23672.519531   \n",
      "2018-09-20  23752.789063  23781.750000  23582.150391  23674.929688   \n",
      "2018-09-21  23848.630859  23971.410156  23764.050781  23869.929688   \n",
      "\n",
      "               Adj Close    Volume  \n",
      "Date                                \n",
      "1965-01-05   1257.719971       0.0  \n",
      "1965-01-06   1263.989990       0.0  \n",
      "1965-01-07   1274.270020       0.0  \n",
      "1965-01-08   1286.430054       0.0  \n",
      "1965-01-11           NaN       NaN  \n",
      "...                  ...       ...  \n",
      "2018-09-17           NaN       NaN  \n",
      "2018-09-18  23420.539063   90600.0  \n",
      "2018-09-19  23672.519531   93600.0  \n",
      "2018-09-20  23674.929688  101600.0  \n",
      "2018-09-21  23869.929688       0.0  \n",
      "\n",
      "[13844 rows x 6 columns]\n",
      "csv_ read\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1995-11-22   663.320007   663.320007   663.320007   663.320007   663.320007   \n",
      "1995-11-23   658.369995   658.369995   658.369995   658.369995   658.369995   \n",
      "1995-11-24   659.369995   659.369995   659.369995   659.369995   659.369995   \n",
      "1995-11-27   645.030029   645.030029   645.030029   645.030029   645.030029   \n",
      "1995-11-28   652.570007   652.570007   652.570007   652.570007   652.570007   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-09-18  2644.295898  2700.193115  2644.295898  2699.949951  2699.949951   \n",
      "2018-09-19  2694.799072  2746.080078  2690.993896  2730.850098  2730.850098   \n",
      "2018-09-20  2732.169922  2743.965088  2724.083984  2729.243896  2729.243896   \n",
      "2018-09-21  2733.874023  2797.485107  2722.031982  2797.485107  2797.485107   \n",
      "2018-09-25  2775.066406  2790.031982  2771.159424  2781.138428  2781.138428   \n",
      "\n",
      "                  Volume  \n",
      "Date                      \n",
      "1995-11-22  0.000000e+00  \n",
      "1995-11-23  0.000000e+00  \n",
      "1995-11-24  0.000000e+00  \n",
      "1995-11-27  0.000000e+00  \n",
      "1995-11-28  0.000000e+00  \n",
      "...                  ...  \n",
      "2018-09-18  1.158000e+05  \n",
      "2018-09-19  1.416000e+05  \n",
      "2018-09-20  1.114000e+05  \n",
      "2018-09-21  1.580000e+05  \n",
      "2018-09-25  2.608383e+09  \n",
      "\n",
      "[5738 rows x 6 columns]\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1995-11-22   663.320007   663.320007   663.320007   663.320007   663.320007   \n",
      "1995-11-23   658.369995   658.369995   658.369995   658.369995   658.369995   \n",
      "1995-11-24   659.369995   659.369995   659.369995   659.369995   659.369995   \n",
      "1995-11-27   645.030029   645.030029   645.030029   645.030029   645.030029   \n",
      "1995-11-28   652.570007   652.570007   652.570007   652.570007   652.570007   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-09-18  2644.295898  2700.193115  2644.295898  2699.949951  2699.949951   \n",
      "2018-09-19  2694.799072  2746.080078  2690.993896  2730.850098  2730.850098   \n",
      "2018-09-20  2732.169922  2743.965088  2724.083984  2729.243896  2729.243896   \n",
      "2018-09-21  2733.874023  2797.485107  2722.031982  2797.485107  2797.485107   \n",
      "2018-09-25  2775.066406  2790.031982  2771.159424  2781.138428  2781.138428   \n",
      "\n",
      "                  Volume  \n",
      "Date                      \n",
      "1995-11-22  0.000000e+00  \n",
      "1995-11-23  0.000000e+00  \n",
      "1995-11-24  0.000000e+00  \n",
      "1995-11-27  0.000000e+00  \n",
      "1995-11-28  0.000000e+00  \n",
      "...                  ...  \n",
      "2018-09-18  1.158000e+05  \n",
      "2018-09-19  1.416000e+05  \n",
      "2018-09-20  1.114000e+05  \n",
      "2018-09-21  1.580000e+05  \n",
      "2018-09-25  2.608383e+09  \n",
      "\n",
      "[5738 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_ read\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1986-12-31   2568.300049   2568.300049   2568.300049   2568.300049   \n",
      "1987-01-01           NaN           NaN           NaN           NaN   \n",
      "1987-01-02   2540.100098   2540.100098   2540.100098   2540.100098   \n",
      "1987-01-05   2552.399902   2552.399902   2552.399902   2552.399902   \n",
      "1987-01-06   2583.899902   2583.899902   2583.899902   2583.899902   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-21  27712.349609  27965.960938  27536.269531  27953.580078   \n",
      "2018-09-24  27783.849609  27783.849609  27425.009766  27499.390625   \n",
      "2018-09-26  27606.810547  28031.810547  27589.369141  27816.869141   \n",
      "2018-09-27  27912.509766  27928.289063  27638.539063  27715.669922   \n",
      "2018-09-28  27879.060547  27927.949219  27672.830078  27788.519531   \n",
      "\n",
      "               Adj Close        Volume  \n",
      "Date                                    \n",
      "1986-12-31   2568.300049  0.000000e+00  \n",
      "1987-01-01           NaN           NaN  \n",
      "1987-01-02   2540.100098  0.000000e+00  \n",
      "1987-01-05   2552.399902  0.000000e+00  \n",
      "1987-01-06   2583.899902  0.000000e+00  \n",
      "...                  ...           ...  \n",
      "2018-09-21  27953.580078  2.777208e+09  \n",
      "2018-09-24  27499.390625  1.511080e+09  \n",
      "2018-09-26  27816.869141  2.338781e+09  \n",
      "2018-09-27  27715.669922  1.440548e+09  \n",
      "2018-09-28  27788.519531  1.636511e+09  \n",
      "\n",
      "[8094 rows x 6 columns]\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1986-12-31   2568.300049   2568.300049   2568.300049   2568.300049   \n",
      "1987-01-01           NaN           NaN           NaN           NaN   \n",
      "1987-01-02   2540.100098   2540.100098   2540.100098   2540.100098   \n",
      "1987-01-05   2552.399902   2552.399902   2552.399902   2552.399902   \n",
      "1987-01-06   2583.899902   2583.899902   2583.899902   2583.899902   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-21  27712.349609  27965.960938  27536.269531  27953.580078   \n",
      "2018-09-24  27783.849609  27783.849609  27425.009766  27499.390625   \n",
      "2018-09-26  27606.810547  28031.810547  27589.369141  27816.869141   \n",
      "2018-09-27  27912.509766  27928.289063  27638.539063  27715.669922   \n",
      "2018-09-28  27879.060547  27927.949219  27672.830078  27788.519531   \n",
      "\n",
      "               Adj Close        Volume  \n",
      "Date                                    \n",
      "1986-12-31   2568.300049  0.000000e+00  \n",
      "1987-01-01           NaN           NaN  \n",
      "1987-01-02   2540.100098  0.000000e+00  \n",
      "1987-01-05   2552.399902  0.000000e+00  \n",
      "1987-01-06   2583.899902  0.000000e+00  \n",
      "...                  ...           ...  \n",
      "2018-09-21  27953.580078  2.777208e+09  \n",
      "2018-09-24  27499.390625  1.511080e+09  \n",
      "2018-09-26  27816.869141  2.338781e+09  \n",
      "2018-09-27  27715.669922  1.440548e+09  \n",
      "2018-09-28  27788.519531  1.636511e+09  \n",
      "\n",
      "[8094 rows x 6 columns]\n",
      "csv_ read\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1997-07-01   4263.109863   4301.770020   4247.660156   4300.859863   \n",
      "1997-07-02   4302.959961   4395.310059   4295.399902   4333.899902   \n",
      "1997-07-03   4335.790039   4393.290039   4299.970215   4323.459961   \n",
      "1997-07-04   4332.700195   4347.589844   4300.580078   4323.819824   \n",
      "1997-07-07   4326.810059   4391.009766   4289.490234   4291.450195   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-10-01  36274.250000  36616.640625  35960.648438  36526.140625   \n",
      "2018-10-03  36602.851563  36602.851563  35911.820313  35975.628906   \n",
      "2018-10-04  35820.531250  35820.531250  35022.121094  35169.160156   \n",
      "2018-10-05  35097.988281  35118.539063  34202.218750  34376.988281   \n",
      "2018-10-08  34412.359375  34636.429688  33974.660156  34474.378906   \n",
      "\n",
      "               Adj Close   Volume  \n",
      "Date                               \n",
      "1997-07-01   4300.859863      0.0  \n",
      "1997-07-02   4333.899902      0.0  \n",
      "1997-07-03   4323.459961      0.0  \n",
      "1997-07-04   4323.819824      0.0  \n",
      "1997-07-07   4291.450195      0.0  \n",
      "...                  ...      ...  \n",
      "2018-10-01  36526.140625  21300.0  \n",
      "2018-10-03  35975.628906  25100.0  \n",
      "2018-10-04  35169.160156  21300.0  \n",
      "2018-10-05  34376.988281  22100.0  \n",
      "2018-10-08  34474.378906  20400.0  \n",
      "\n",
      "[5363 rows x 6 columns]\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1997-07-01   4263.109863   4301.770020   4247.660156   4300.859863   \n",
      "1997-07-02   4302.959961   4395.310059   4295.399902   4333.899902   \n",
      "1997-07-03   4335.790039   4393.290039   4299.970215   4323.459961   \n",
      "1997-07-04   4332.700195   4347.589844   4300.580078   4323.819824   \n",
      "1997-07-07   4326.810059   4391.009766   4289.490234   4291.450195   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-10-01  36274.250000  36616.640625  35960.648438  36526.140625   \n",
      "2018-10-03  36602.851563  36602.851563  35911.820313  35975.628906   \n",
      "2018-10-04  35820.531250  35820.531250  35022.121094  35169.160156   \n",
      "2018-10-05  35097.988281  35118.539063  34202.218750  34376.988281   \n",
      "2018-10-08  34412.359375  34636.429688  33974.660156  34474.378906   \n",
      "\n",
      "               Adj Close   Volume  \n",
      "Date                               \n",
      "1997-07-01   4300.859863      0.0  \n",
      "1997-07-02   4333.899902      0.0  \n",
      "1997-07-03   4323.459961      0.0  \n",
      "1997-07-04   4323.819824      0.0  \n",
      "1997-07-07   4291.450195      0.0  \n",
      "...                  ...      ...  \n",
      "2018-10-01  36526.140625  21300.0  \n",
      "2018-10-03  35975.628906  25100.0  \n",
      "2018-10-04  35169.160156  21300.0  \n",
      "2018-10-05  34376.988281  22100.0  \n",
      "2018-10-08  34474.378906  20400.0  \n",
      "\n",
      "[5363 rows x 6 columns]\n",
      "csv_ read\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1990-11-09  1377.300049  1377.300049  1377.300049  1377.300049  1377.300049   \n",
      "1990-11-12  1388.099976  1408.099976  1388.099976  1407.500000  1407.500000   \n",
      "1990-11-13  1412.199951  1429.400024  1411.400024  1415.199951  1415.199951   \n",
      "1990-11-14  1413.599976  1413.599976  1402.099976  1410.300049  1410.300049   \n",
      "1990-11-15  1410.599976  1416.699951  1405.099976  1405.699951  1405.699951   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-10-02  9087.320313  9087.320313  9087.320313  9087.320313  9087.320313   \n",
      "2018-10-03  9175.209961  9175.209961  9175.209961  9175.209961  9175.209961   \n",
      "2018-10-04  9097.519531  9097.519531  9097.519531  9097.519531  9097.519531   \n",
      "2018-10-05  9042.080078  9042.080078  9042.080078  9042.080078  9042.080078   \n",
      "2018-10-08  8964.139648  8964.139648  8964.139648  8964.139648  8964.139648   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "1990-11-09     0.0  \n",
      "1990-11-12     0.0  \n",
      "1990-11-13     0.0  \n",
      "1990-11-14     0.0  \n",
      "1990-11-15     0.0  \n",
      "...            ...  \n",
      "2018-10-02     0.0  \n",
      "2018-10-03     0.0  \n",
      "2018-10-04     0.0  \n",
      "2018-10-05     0.0  \n",
      "2018-10-08     0.0  \n",
      "\n",
      "[7171 rows x 6 columns]\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1990-11-09  1377.300049  1377.300049  1377.300049  1377.300049  1377.300049   \n",
      "1990-11-12  1388.099976  1408.099976  1388.099976  1407.500000  1407.500000   \n",
      "1990-11-13  1412.199951  1429.400024  1411.400024  1415.199951  1415.199951   \n",
      "1990-11-14  1413.599976  1413.599976  1402.099976  1410.300049  1410.300049   \n",
      "1990-11-15  1410.599976  1416.699951  1405.099976  1405.699951  1405.699951   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-10-02  9087.320313  9087.320313  9087.320313  9087.320313  9087.320313   \n",
      "2018-10-03  9175.209961  9175.209961  9175.209961  9175.209961  9175.209961   \n",
      "2018-10-04  9097.519531  9097.519531  9097.519531  9097.519531  9097.519531   \n",
      "2018-10-05  9042.080078  9042.080078  9042.080078  9042.080078  9042.080078   \n",
      "2018-10-08  8964.139648  8964.139648  8964.139648  8964.139648  8964.139648   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "1990-11-09     0.0  \n",
      "1990-11-12     0.0  \n",
      "1990-11-13     0.0  \n",
      "1990-11-14     0.0  \n",
      "1990-11-15     0.0  \n",
      "...            ...  \n",
      "2018-10-02     0.0  \n",
      "2018-10-03     0.0  \n",
      "2018-10-04     0.0  \n",
      "2018-10-05     0.0  \n",
      "2018-10-08     0.0  \n",
      "\n",
      "[7171 rows x 6 columns]\n",
      "csv_ read\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1993-04-27     24.799999     25.400000     24.500000     24.500000   \n",
      "1993-04-28     24.500000     24.600000     23.700001     24.299999   \n",
      "1993-04-29     24.299999     24.799999     23.700001     23.700001   \n",
      "1993-04-30     23.700001     24.200001     23.700001     24.100000   \n",
      "1993-05-03     24.100000     24.400000     23.799999     24.100000   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-24  79447.000000  79447.000000  77857.000000  77984.000000   \n",
      "2018-09-25  77980.000000  78688.000000  77005.000000  78630.000000   \n",
      "2018-09-26  78634.000000  79461.000000  78530.000000  78656.000000   \n",
      "2018-09-27  78676.000000  80107.000000  78676.000000  80000.000000   \n",
      "2018-09-28  80000.000000  80000.000000  78967.000000  79342.000000   \n",
      "\n",
      "               Adj Close     Volume  \n",
      "Date                                 \n",
      "1993-04-27     24.500000        0.0  \n",
      "1993-04-28     24.299999        0.0  \n",
      "1993-04-29     23.700001        0.0  \n",
      "1993-04-30     24.100000        0.0  \n",
      "1993-05-03     24.100000        0.0  \n",
      "...                  ...        ...  \n",
      "2018-09-24  77984.000000        0.0  \n",
      "2018-09-25  78630.000000  3700400.0  \n",
      "2018-09-26  78656.000000  3735300.0  \n",
      "2018-09-27  80000.000000  4475000.0  \n",
      "2018-09-28  79342.000000  4061400.0  \n",
      "\n",
      "[6472 rows x 6 columns]\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "1993-04-27     24.799999     25.400000     24.500000     24.500000   \n",
      "1993-04-28     24.500000     24.600000     23.700001     24.299999   \n",
      "1993-04-29     24.299999     24.799999     23.700001     23.700001   \n",
      "1993-04-30     23.700001     24.200001     23.700001     24.100000   \n",
      "1993-05-03     24.100000     24.400000     23.799999     24.100000   \n",
      "...                  ...           ...           ...           ...   \n",
      "2018-09-24  79447.000000  79447.000000  77857.000000  77984.000000   \n",
      "2018-09-25  77980.000000  78688.000000  77005.000000  78630.000000   \n",
      "2018-09-26  78634.000000  79461.000000  78530.000000  78656.000000   \n",
      "2018-09-27  78676.000000  80107.000000  78676.000000  80000.000000   \n",
      "2018-09-28  80000.000000  80000.000000  78967.000000  79342.000000   \n",
      "\n",
      "               Adj Close     Volume  \n",
      "Date                                 \n",
      "1993-04-27     24.500000        0.0  \n",
      "1993-04-28     24.299999        0.0  \n",
      "1993-04-29     23.700001        0.0  \n",
      "1993-04-30     24.100000        0.0  \n",
      "1993-05-03     24.100000        0.0  \n",
      "...                  ...        ...  \n",
      "2018-09-24  77984.000000        0.0  \n",
      "2018-09-25  78630.000000  3700400.0  \n",
      "2018-09-26  78656.000000  3735300.0  \n",
      "2018-09-27  80000.000000  4475000.0  \n",
      "2018-09-28  79342.000000  4061400.0  \n",
      "\n",
      "[6472 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets_original = ['^GSPC.csv', '^N225.csv', 'SSE.csv','^HSI.csv', '^BSESN.csv',\\\n",
    "                     '^SSMI.csv', '^BVSP.csv']\n",
    "dataset_names = ['S&P 500', 'N225', 'SSE', 'HSI', 'BSESN', 'SMI', 'BVSP']\n",
    "\n",
    "# specify drawdown thresholds for crashes (determined in exploration.ipynb):\n",
    "crash_thresholds = [-0.0936, -0.1101, -0.1269, -0.1470, -0.1703, -0.1106, -0.2344] # <-- Jacobsson\n",
    "# crash_thresholds = [-0.1053, -0.1495, -0.1706, -0.2334, -0.1563, -0.1492, -0.2264] # <-- Sornette\n",
    "months = [1, 3, 6]              # <-- predict if crash n months ahead (use: 1, 3 or 6)\n",
    "data = DataLoader(datasets_original, dataset_names)\n",
    "datasets_revised, crashes = data.get_data_revised(crash_thresholds)\n",
    "dfs_x, dfs_y = data.get_dfs_xy(months=months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a58c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Find best parameters with grid search -------------------- #\n",
    "model_name = 'Logistic Regression'\n",
    "test_data = 'S&P 500'\n",
    "month_prediction = 3\n",
    "beta = 2\n",
    "\n",
    "index_test = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "index_month = [i for i, m in enumerate(months) if m == month_prediction][0]\n",
    "training_set_names = list(dataset_names)\n",
    "training_set_names.pop(index_test)\n",
    "dfs_x_training = list(dfs_x)\n",
    "dfs_x_training.pop(index_test)\n",
    "dfs_y_training = list(dfs_y)\n",
    "dfs_y_training.pop(index_test)\n",
    "x_train, y_train, _, _ = data.get_train_test(dfs_x_training, dfs_y_training, \\\n",
    "            training_set_names, test_data=None)\n",
    "y_train = y_train[:, index_month].astype(int)\n",
    "\n",
    "# Find parameters with grid search:\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=beta)\n",
    "# param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'class_weight': [{0:.05, 1:.95}, {0:.04, 1:.96}, \\\n",
    "#               {0:.03, 1:.97}, {0:.025, 1:.975}, {0:.02, 1:.98}]}]   # <-- 1 month\n",
    "param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'class_weight': [{0:.07, 1:.93}, {0:.06, 1:.94}, \\\n",
    "                {0:.05, 1:.95}, {0:.04, 1:.96}]}]   # <-- 3 months\n",
    "# param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'class_weight': [{0:.11, 1:.89}, {0:.1, 1:.9},\\\n",
    "#                 {0:.09, 1:.91}, {0:.08, 1:.92}]}]   # <-- 6 months\n",
    "\n",
    "clf = GridSearchCV(linear_model.LogisticRegression(penalty='l2'), param_grid, scoring=fbeta_scorer, return_train_score=True) \n",
    "model = clf.fit(x_train, y_train)\n",
    "labels = model.cv_results_['params']\n",
    "\n",
    "\n",
    "tr_score = model.cv_results_['mean_train_score']\n",
    "t_score = model.cv_results_['mean_test_score']\n",
    "rcParams['figure.figsize'] = 8, 4\n",
    "plt.bar(x=np.arange(len(tr_score)) - 0.2,width=0.4, height=tr_score, color='lightblue', label='train score')\n",
    "plt.bar(x=np.arange(len(t_score)) + 0.2,width=0.4, height=t_score, color='blue', label='test score')\n",
    "plt.title('Find best parameters with F beta score (beta=2)')\n",
    "plt.xticks(np.arange(len(labels)), labels, rotation=90)\n",
    "plt.ylabel('F-Beta score (beta=2)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3078dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_score = model.cv_results_['mean_train_score']\n",
    "clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33909e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406bbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Train Logistic Regression -------------------- #\n",
    "class_weight = {0:.06, 1:.94}\n",
    "C = 1\n",
    "index_test = [i for i, name in enumerate(dataset_names) if name == test_data][0]\n",
    "index_month = [i for i, m in enumerate(months) if m == month_prediction][0]\n",
    "training_set_names = list(dataset_names)\n",
    "training_set_names.pop(index_test)\n",
    "dfs_x_training = list(dfs_x)\n",
    "dfs_x_training.pop(index_test)\n",
    "dfs_y_training = list(dfs_y)\n",
    "dfs_y_training.pop(index_test)\n",
    "y_train_all, y_val_all = [], []\n",
    "y_pred_train_all, y_pred_val_all = [], []\n",
    "for val_data in training_set_names:\n",
    "    x_train, y_train, x_val, y_val = data.get_train_test(dfs_x_training, dfs_y_training, \\\n",
    "            training_set_names, test_data=val_data)\n",
    "    y_train, y_val = y_train[:, index_month].astype(int), y_val[:, index_month].astype(int)\n",
    "    y_train_all.append(y_train)\n",
    "    y_val_all.append(y_val)\n",
    "    print('Train ' + str(model_name) + ' - validation data: ' + str(val_data))\n",
    "    clf = linear_model.LogisticRegression(C=C, class_weight=class_weight)\n",
    "    model = clf.fit(x_train, y_train)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_train_all.append(y_pred_train)\n",
    "    y_pred_val = model.predict(x_val)\n",
    "    y_pred_val_all.append(y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Evaluate results -------------------- #\n",
    "eval_ = EvaluateResults(y_train_all, y_val_all, y_pred_train_all, y_pred_val_all, model_name, test_data)\n",
    "beta = 2\n",
    "threshold = None\n",
    "print(model_name)\n",
    "print('\\n')\n",
    "print('Predict crash in:               ' + str(month_prediction) + ' months')\n",
    "print('Number of features:             ' + str(dfs_x[0].shape[1]))\n",
    "print('Number of rows in training set: ' + str(len(y_pred_train_all[0]) + len(y_pred_val_all[0])))\n",
    "print('\\n')\n",
    "eval_.training_results(threshold, training_set_names, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Test model -------------------- #\n",
    "x_train, y_train, x_test, y_test = data.get_train_test(dfs_x, dfs_y, dataset_names, test_data=test_data)\n",
    "y_train, y_test = y_train[:, index_month].astype(int), y_test[:, index_month].astype(int)\n",
    "lm = linear_model.LogisticRegression(C=C, class_weight=class_weight)\n",
    "model = lm.fit(x_train, y_train)\n",
    "y_pred_test_bin = model.predict(x_test).astype(int)\n",
    "threshold = None\n",
    "_ = eval_.test_results(y_test, y_pred_test_bin, threshold, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a86f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Plot test results -------------------- #\n",
    "df = datasets_revised[index_test].reindex(dfs_x[index_test].index)\n",
    "df['y'] = y_test\n",
    "df['y_pred'] = y_pred_test_bin\n",
    "c = crashes[index_test]\n",
    "t_start = ['1956-01-01', '1971-01-01', '1976-01-01', '1983-01-01', '1995-01-01', '2004-01-01', '2010-01-01']\n",
    "t_end = ['1963-01-01', '1981-01-01', '1983-01-01', '1988-01-01', '2003-01-01', '2010-01-01', '2016-01-01']\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "eval_.plot_test_results(df, c, t_start, t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7597564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Current prediction S&P 500 -------------------- #\n",
    "# train on all available data:\n",
    "os.chdir('/Users/Hp/VS CODE/Stock market crash prediction')\n",
    "x_train, y_train, _, _ = data.get_train_test(dfs_x, dfs_y, dataset_names, test_data=None)\n",
    "C = [1, 1, 1]\n",
    "class_weights = [{0:.06, 1:.94}, {0:.06, 1:.94}, {0:.08, 1:.92}]\n",
    "dataset_original = ['^GSPC_11-05.csv']\n",
    "dataset_name = ['S&P 500']\n",
    "crash_threshold = [-0.0936]\n",
    "data_new = DataLoader(dataset_original, dataset_name)\n",
    "dataset_revised, crashes = data_new.get_data_revised(crash_threshold)\n",
    "dfs_x_new, dfs_y_new = data_new.get_dfs_xy_predict(months=months)\n",
    "x_new, _, _, _ = data_new.get_train_test(dfs_x_new, dfs_y_new, dataset_name, test_data=None)\n",
    "\n",
    "os.chdir('/Users/Hp/VS CODE/Stock market crash prediction')\n",
    "for index_month in range(len(months)):\n",
    "    y_train_ = y_train[:, index_month].astype(int)\n",
    "    lm = linear_model.LogisticRegression(C=C[index_month], class_weight=class_weights[index_month])\n",
    "    model = lm.fit(x_train, y_train_)\n",
    "    filename = 'logreg_model_{}months.sav'.format(months[index_month])\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    y_pred_new_bin = model.predict(x_new).astype(int)\n",
    "    current_pred = np.dot(np.linspace(0,1,21) / sum(np.linspace(0,1,21)), y_pred_new_bin[-21:])\n",
    "    print(str(model_name) + ' prediction of a crash within ' + str(months[index_month]) \\\n",
    "          + ' months: ' + str(np.round(current_pred, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62f36f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89087f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf9f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33affb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
